{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giriş İşlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install kagglehub pandas transformers datasets scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \".\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Veri Kümesi Okuma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesi okuma fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_kumesi_oku(veri_kumesi_adi: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Kaggle veri kümesini indirir ve döndürür.\n",
    "    \n",
    "    Args:\n",
    "        veri_kumesi_adi (str): Kaggle veri kümesinin yolu.\n",
    "        gecici_yol (str): Geçici dosya yolu.\n",
    "    Returns:\n",
    "        pd.DataFrame: İndirilen veri kümesi.\n",
    "    \"\"\"\n",
    "    # Kaggle veri kümesini indir\n",
    "    gecici_yol = os.path.join(kagglehub.dataset_download(veri_kumesi_adi), \"TurkishSMSCollection.csv\")\n",
    "    return pd.read_csv(gecici_yol, sep=\";\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesini oku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kümesi bilgileri\n",
    "dataset_name = \"onurkarasoy/turkish-sms-collection\"\n",
    "\n",
    "veri_kumesi = veri_kumesi_oku(dataset_name)\n",
    "veri_kumesi.head(10)  # İlk 10 satırı göster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesinin gereksiz kolonlarını silme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tohum_degeri = 571\n",
    "# gereksiz sütunları kaldır\n",
    "veri_kumesi = veri_kumesi[['Message', 'Group']]\n",
    "# veri kümesini karıştır\n",
    "veri_kumesi.head(10)  # İlk 10 satırı göster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesini karıştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karismis_veri_kumesi = veri_kumesi.sample(frac=1, random_state=tohum_degeri).reset_index(drop=True)\n",
    "karismis_veri_kumesi.head(10)  # İlk 10 satırı göster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümesini eğitim ve sınama olarak parçalama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def veri_kumesini_oranli_bol(veri_kumesi, test_orani=0.2, tohum_degeri=42):\n",
    "    \"\"\"\n",
    "    Veri kümesini, Group kolonundaki değerlerin oranlarını koruyarak böler.\n",
    "    \n",
    "    Args:\n",
    "        veri_kumesi (pd.DataFrame): Bölünecek veri kümesi\n",
    "        test_orani (float): Test veri kümesinin oranı (varsayılan: 0.2)\n",
    "        tohum_degeri (int): Random state değeri (tekrarlanabilirlik için)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (egitim_veri_kumesi, test_veri_kumesi) - Oransal olarak bölünmüş veri kümeleri\n",
    "    \"\"\"\n",
    "    # Benzersiz grup değerlerini bul\n",
    "    gruplar = veri_kumesi['Group'].unique()\n",
    "    \n",
    "    egitim_liste = []\n",
    "    test_liste = []\n",
    "    \n",
    "    # Her grup için ayrı ayrı bölme işlemi yap\n",
    "    for grup in gruplar:\n",
    "        # Sadece bu gruba ait verileri seç\n",
    "        grup_verisi = veri_kumesi[veri_kumesi['Group'] == grup]\n",
    "        \n",
    "        # Bu grubu karıştır\n",
    "        karisik_grup = grup_verisi.sample(frac=1, random_state=tohum_degeri)\n",
    "        \n",
    "        # Bölme noktasını hesapla\n",
    "        bolme_noktasi = int(len(karisik_grup) * test_orani)\n",
    "        \n",
    "        # Bu gruptan test ve eğitim verilerini ayır\n",
    "        test_grubu = karisik_grup[:bolme_noktasi]\n",
    "        egitim_grubu = karisik_grup[bolme_noktasi:]\n",
    "        \n",
    "        # Listelere ekle\n",
    "        test_liste.append(test_grubu)\n",
    "        egitim_liste.append(egitim_grubu)\n",
    "    \n",
    "    # Grupları birleştir\n",
    "    test_veri_kumesi = pd.concat(test_liste).reset_index(drop=True)\n",
    "    egitim_veri_kumesi = pd.concat(egitim_liste).reset_index(drop=True)\n",
    "    \n",
    "    # Son bir karıştırma işlemi\n",
    "    test_veri_kumesi = test_veri_kumesi.sample(frac=1, random_state=tohum_degeri).reset_index(drop=True)\n",
    "    egitim_veri_kumesi = egitim_veri_kumesi.sample(frac=1, random_state=tohum_degeri).reset_index(drop=True)\n",
    "    \n",
    "    return egitim_veri_kumesi, test_veri_kumesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egitim_veri, test_veri = veri_kumesini_oranli_bol(karismis_veri_kumesi, tohum_degeri=tohum_degeri)\n",
    "egitim_veri.head(5)  # İlk 5 satırı göster\n",
    "test_veri.head(5)  # İlk 5 satırı göster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri kümelerini eğitime hazır hale getirme fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri kümesini hazırla\n",
    "def verileri_hazirla(df, tokenizer):\n",
    "    # Group değerlerini 0 ve 1'e dönüştür (Group=1 -> 0, Group=2 -> 1)\n",
    "    # BERT sınıflandırma için 0-based indeksler kullanır\n",
    "    labels = df[\"Group\"].apply(lambda x: 0 if x == 1 else 1).tolist()\n",
    "    \n",
    "    # Dataset'e dönüştür\n",
    "    dataset = Dataset.from_dict({\n",
    "        \"text\": df[\"Message\"].tolist(),\n",
    "        \"label\": labels\n",
    "    })\n",
    "    \n",
    "    # Tokenize işlemi\n",
    "    def tokenize_function(examples):\n",
    "        return tokenizer(\n",
    "            examples[\"text\"], \n",
    "            padding=\"max_length\", \n",
    "            truncation=True, \n",
    "            max_length=512,  # BERT için genellikle 512 kullanılır\n",
    "        )\n",
    "    \n",
    "    tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "    return tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sınama sonucu hesaplama fonksiyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ölçüt hesaplama fonksiyonu\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Eğitim işlemleri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model yükleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_adi = \"dbmdz/bert-base-turkish-128k-cased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_adi)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_adi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim ve test veri kümelerini hazırla\n",
    "egitim_dataset = verileri_hazirla(egitim_veri, tokenizer)\n",
    "test_dataset = verileri_hazirla(test_veri, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitim argümanlarını ve eğiticiyi ayarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim argümanlarını tanımla\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./sonuclar\",\n",
    "    num_train_epochs=1,  # 1 epoch\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "# Eğiticiyi oluştur\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=egitim_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitim ve sınama işlemleri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli eğit\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Değerlendirme\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Değerlendirme sonuçları: {eval_results}\")\n",
    "sonuc_json_path = os.path.join(root_dir, \"degerlendirme_sonucu.json\")\n",
    "with open(sonuc_json_path, \"w\") as f:\n",
    "    import json\n",
    "    json.dump(eval_results, f, indent=4)\n",
    "print(f\"Değerlendirme sonuçları {sonuc_json_path} dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitilen modeli kaydetme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitilen modeli kaydet\n",
    "model_save_path = os.path.join(root_dir, \"egitilen_model\")\n",
    "if not os.path.exists(model_save_path):\n",
    "    os.makedirs(model_save_path)\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
